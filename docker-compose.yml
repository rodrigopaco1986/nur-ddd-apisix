version: '3.9'
services:
  #####API GATEWAY SERVICES######
  
  #key-value store (used for apisix)
  etcd:
    image: bitnami/etcd:3.5
    container_name: etcd
    environment:
      - ALLOW_NONE_AUTHENTICATION=yes
      - ETCD_ADVERTISE_CLIENT_URLS=http://etcd:2379
      - ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379
    ports:
      - "2379:2379"
    volumes:
      - etcd_data:/bitnami/etcd
    networks:
      - shared_services_network

  # dynamic, real-time, high-performance API Gateway
  apisix:
    image: apache/apisix:3.12.0-debian
    container_name: apisix
    restart: always
    depends_on:
      - etcd
      - vault
    environment:
      - APISIX_ADMIN_KEY=edd1c9f034335f136f87ad84b625c8f1
      - ETCD_HOST=http://etcd:2379
      - VAULT_ADDR=http://vault:8200
      - VAULT_TOKEN=root
      - VAULT_PREFIX=secret/data/apisix/oauth
    volumes:
      - ./apisix.yaml:/usr/local/apisix/conf/config.yaml:ro
    ports:
      - "9080:9080"   # proxy listen
      - "9180:9180"   # admin API
    networks:
      - shared_services_network

  # admin dashboard for apisix
  apisix-dashboard:
    image: apache/apisix-dashboard:3.0.1-alpine
    container_name: apisix-dashboard
    restart: always
    depends_on:
      - apisix
      - etcd
    volumes:
      - ./dashboard.yaml:/usr/local/apisix-dashboard/conf/conf.yaml:ro
    ports:
      - "9000:9000"
    networks:
      - shared_services_network

  # Secure, store, and tightly control access to tokens, passwords, certificates, encryption keys for protecting secrets
  vault:
    hostname: vault
    container_name: vault
    image: vault:1.13.3
    environment:
      VAULT_ADDR: http://0.0.0.0:8200
      VAULT_API_ADDR: http://0.0.0.0:8200
    ports:
      - 8200:8200
    volumes:
      - ./volumes/vault/file:/vault/file:rw
      - ./vault/config/config.json:/vault/config/config.json:ro
    cap_add:
      - IPC_LOCK
    entrypoint: vault server -dev -dev-listen-address="0.0.0.0:8200" -dev-root-token-id="root"
    networks:
      - shared_services_network

  # script to init secrets in vault (oauth certs and client keys)
  vault-init:
    container_name: vault-init
    image: vault:1.13.3
    volumes:
      - ./vault/init/vault-init.sh:/vault-init.sh
      - ./vault/config/app-policy.hcl:/app-policy.hcl
    depends_on:
      - vault
    restart: "no"
    entrypoint: sh -c "/vault-init.sh"
    networks:
      - shared_services_network
  
  #####IDENTITY APP - API GATEWAY SETTINGS CREATOR######

  # identity laravel app
  auth-app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: auth-app
    restart: on-failure
    working_dir: /var/www/html
    volumes:
      - .:/var/www/html
      - /var/www/html/vendor
    networks:
      - shared_services_network
    depends_on:
      - db
      - apisix
    env_file:
      - .env
    environment:
      - APP_ENV=local
      - APP_DEBUG=true
      - APP_KEY=${APP_KEY}
      - DB_CONNECTION=${DB_CONNECTION}
      - DB_HOST=${DB_HOST}
      - DB_PORT=${DB_PORT}
      - DB_DATABASE=${DB_DATABASE}
      - DB_USERNAME=${DB_USERNAME}
      - DB_PASSWORD=${DB_PASSWORD}
    extra_hosts:
      - "myinvoice.local:172.18.0.2"
    healthcheck:
      test: ["CMD", "php", "-r", "echo @fsockopen('localhost', 9000) ? 'Healthy' : 'Unhealthy';"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # identity app web server
  webserver:
    image: nginx:latest
    container_name: nginx_server
    restart: on-failure
    ports:
      - "8000:80"
      - "8443:443"
    volumes:
      - .:/var/www/html
      - ./nginx.conf:/etc/nginx/conf.d/default.conf
      - ./certs:/etc/nginx/certs 
    networks:
      - shared_services_network
    depends_on:
      - auth-app
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # identity app database
  db:
    image: mysql:8.0
    container_name: mysql_db
    restart: on-failure
    ports:
      - "3307:3306"
    volumes:
      - mysql_data:/var/lib/mysql
    networks:
      - shared_services_network
    env_file:
      - .env
    environment:
      MYSQL_DATABASE: ${DB_DATABASE}
      MYSQL_ROOT_PASSWORD: root
      MYSQL_USER: ${DB_USERNAME}
      MYSQL_PASSWORD: ${DB_PASSWORD}
    command: ["--default-authentication-plugin=mysql_native_password"]
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
  
  #####BROKER SERVICES######

  # centralized service used by Apache Kafka to manage and coordinate a distributed system of Kafka brokers
  zookeeper:
    image: bitnami/zookeeper:latest
    container_name: zookeeper
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    networks:
      - shared_services_network
  
  # broker
  kafka:
    image: bitnami/kafka:3.4.0-debian-11-r15
    container_name: kafka
    depends_on:
      - zookeeper
    environment:
      - KAFKA_ENABLE_KRAFT=no
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_LISTENERS=PLAINTEXT://:9092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - ALLOW_PLAINTEXT_LISTENER=yes
    networks:
      - shared_services_network
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions.sh", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
  
  # script to create topics into kafka
  kafka-init:
    container_name: kafka-init
    image: bitnami/kafka:3.4.0-debian-11-r15
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint: sh -c "/create_topics.sh"
    volumes:
      - ./kafka/create_topics.sh:/create_topics.sh:ro
    networks:
      - shared_services_network
    restart: "no"
  
  # admin dashboard for kafka
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka_ui
    depends_on:
      - kafka
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: "kafka:9092"
    networks:
      - shared_services_network
    ports:
      - "9001:8080"

  # kafka consumer for patient micro service, so we can create an user in the identity app
  auth-kafka-patient-consumer:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: auth_kafka_patient_consumer
    working_dir: /var/www/html
    restart: unless-stopped
    command: php artisan kafka:consume-patients
    volumes:
      - .:/var/www/html
      - /var/www/html/vendor
    networks:
      - shared_services_network
    depends_on:
      kafka:
        condition: service_started
      auth-app:
        condition: service_started
      db:
        condition: service_healthy
    env_file:
      - .env
    environment:
      - APP_ENV=production
      - APP_DEBUG=true
      - APP_KEY=${APP_KEY}
      - DB_CONNECTION=${DB_CONNECTION}
      - DB_HOST=${DB_HOST}
      - DB_PORT=${DB_PORT}
      - DB_DATABASE=${DB_DATABASE}
      - DB_USERNAME=${DB_USERNAME}
      - DB_PASSWORD=${DB_PASSWORD}
      - QUEUE_CONNECTION=database
    healthcheck:
      test: ["CMD", "php", "-r", "echo @fsockopen('localhost', 9000) ? 'Healthy' : 'Unhealthy';"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  #####   OBSERVABILITY SERVICES   ######

  # OpenTelemetry Collector: The central pipeline for all telemetry data
  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    container_name: otel_collector
    restart: unless-stopped
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ./otel/otel-collector-config.yaml:/etc/otel-collector-config.yaml:ro
    ports:
      - "4317:4317" # OTLP gRPC receiver
      - "4318:4318" # OTLP HTTP receiver (for traces and logs from APISIX)
    depends_on:
      apisix:
        condition: service_started
      jaeger-all-in-one:
        condition: service_started
      loki:
        condition: service_started
      prometheus:
        condition: service_started
    networks:
      - shared_services_network

  # Jaeger: For storing and visualizing traces
  jaeger-all-in-one:
    image: jaegertracing/all-in-one:latest
    container_name: jaeger
    restart: unless-stopped
    ports:
      - "16686:16686" # Jaeger UI
    networks:
      - shared_services_network

  # Loki: For storing logs
  loki:
    image: grafana/loki:latest
    container_name: loki
    restart: unless-stopped
    ports:
      - "3100:3100" # Loki API
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - shared_services_network
  
  # Prometheus: For scraping and storing metrics
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    volumes:
      - ./otel/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "9090:9090" # Prometheus UI
    command: '--config.file=/etc/prometheus/prometheus.yml'
    networks:
      - shared_services_network
  
  # Grafana: For visualizing metrics and logs
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    ports:
      - "3000:3000" # Grafana UI
    volumes:
      - grafana_data:/var/lib/grafana
      # This bind mount provides the provisioning files for datasources and dashboards.
      # It maps your local './grafana/provisioning' directory to the correct directory inside the container.
      - ./grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus
      - loki
    networks:
      - shared_services_network
  
networks:
  shared_services_network:
    driver: bridge
    name: shared-services-network

volumes:
  etcd_data:
    driver: local
  laravel_app:
  mysql_data:
  prometheus_data:
  grafana_data:
